diff --git a/marllib/envs/base_env/__init__.py b/marllib/envs/base_env/__init__.py
index 26c2214..45962a8 100644
--- a/marllib/envs/base_env/__init__.py
+++ b/marllib/envs/base_env/__init__.py
@@ -22,6 +22,24 @@
 
 ENV_REGISTRY = {}
 
+try:
+    from marllib.envs.base_env.cyborg import RLlibCBG
+    ENV_REGISTRY["cyborg"] = RLlibCBG
+except Exception as e:
+    ENV_REGISTRY["cyborg"] = str(e)
+
+try:
+    from marllib.envs.base_env.wmt import RLlibWMT
+    ENV_REGISTRY["wmt"] = RLlibWMT
+except Exception as e:
+    ENV_REGISTRY["wmt"] = str(e)
+
+try:
+    from marllib.envs.base_env.mcy import RLlibMCY
+    ENV_REGISTRY["mcy"] = RLlibMCY
+except Exception as e:
+    ENV_REGISTRY["mcy"] = str(e)
+
 try:
     from marllib.envs.base_env.gymnasium_mamujoco import RLlibGymnasiumRoboticsMAMujoco
     ENV_REGISTRY["gymnasium_mamujoco"] = RLlibGymnasiumRoboticsMAMujoco
diff --git a/marllib/envs/base_env/config/cyborg.yaml b/marllib/envs/base_env/config/cyborg.yaml
new file mode 100644
index 0000000..16da3ca
--- /dev/null
+++ b/marllib/envs/base_env/config/cyborg.yaml
@@ -0,0 +1,47 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+env: cyborg
+
+env_args:
+  map_name: "cage3" # others can be found in cyborg.py
+  environment: "sim"
+  env_config: null
+  agents: null
+  seed: null
+  drone_swarm_scenario_configuration:
+    max_length_data_links: 30
+    data_link_bandwidth: 100
+    num_drones: 18
+    starting_num_red: 0
+    starting_positions: null
+    default_red_agent: null
+    red_spawn_rate: 0.05
+    red_internal_only: True
+    agent_to_drone_mapping: null
+    maximum_steps: 500
+    all_external: False
+
+mask_flag: False
+global_state_flag: False
+opp_action_in_cc: True
+agent_level_batch_update: False
diff --git a/marllib/envs/base_env/config/mcy.yaml b/marllib/envs/base_env/config/mcy.yaml
new file mode 100644
index 0000000..5a637ce
--- /dev/null
+++ b/marllib/envs/base_env/config/mcy.yaml
@@ -0,0 +1,34 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+env: mcy
+
+env_args:
+  map_name: "moving_company" # others can be found in mcy.py
+  size: 6
+  seed: 42
+  max_cycles: 30
+
+mask_flag: False
+global_state_flag: False
+opp_action_in_cc: True
+agent_level_batch_update: False
\ No newline at end of file
diff --git a/marllib/envs/base_env/config/wmt.yaml b/marllib/envs/base_env/config/wmt.yaml
new file mode 100644
index 0000000..c752371
--- /dev/null
+++ b/marllib/envs/base_env/config/wmt.yaml
@@ -0,0 +1,35 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+env: wmt
+
+env_args:
+  map_name: "warehouse_management" # others can be found in mcy.py
+  grid_size: [10, 10]
+  agents_number: 3
+  view_size: 3
+  max_cycles: 100
+
+mask_flag: False
+global_state_flag: False
+opp_action_in_cc: True
+agent_level_batch_update: False
\ No newline at end of file
diff --git a/marllib/envs/base_env/cyborg.py b/marllib/envs/base_env/cyborg.py
new file mode 100644
index 0000000..a72f257
--- /dev/null
+++ b/marllib/envs/base_env/cyborg.py
@@ -0,0 +1,130 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.sys._get
+
+import inspect
+import time
+
+from typing import Dict, Union
+from CybORG.Tests.utils import CustomGenerator
+from ray.rllib.env.multi_agent_env import MultiAgentEnv
+from gym.spaces import Dict as GymDict, Discrete, Box
+import supersuit as ss
+from ray.rllib.env import PettingZooEnv, ParallelPettingZooEnv
+from gym import spaces
+from CybORG import CybORG
+from CybORG.Simulator.Scenarios import DroneSwarmScenarioGenerator
+from CybORG.Agents.Wrappers import PettingZooParallelWrapper
+
+
+def create_env(environment: str = "sim", env_config=None, agents: dict = None,
+               seed: Union[int, CustomGenerator] = None,
+               drone_swarm_scenario_configuration: Dict = {}) -> PettingZooParallelWrapper:
+    sg = DroneSwarmScenarioGenerator(**drone_swarm_scenario_configuration)
+    env = CybORG(scenario_generator=sg, environment=environment,
+                 env_config=env_config, agents=agents, seed=seed)
+    return PettingZooParallelWrapper(env)
+
+
+REGISTRY = {}
+REGISTRY["cage3"] = create_env
+
+policy_mapping_dict = {
+    "cage3": {
+        "description": "CybORG 3rd CAGE Challenge",
+        "team_prefix": ("agent_",),
+        "all_agents_one_policy": True,
+        "one_agent_one_policy": True,
+    }
+}
+
+
+class RLlibCBG(MultiAgentEnv):
+
+    def __init__(self, env_config):
+        map = env_config["map_name"]
+        env_config.pop("map_name", None)
+        self.env = REGISTRY[map](**env_config)
+
+        # keep obs and action dim same across agents
+        # pad_action_space_v0 will auto mask the padding actions
+        # env = ss.pad_observations_v0(env)
+        # env = ss.pad_action_space_v0(env)
+
+        # self.env = ParallelPettingZooEnv(env)
+
+        observation_space = self.env.observation_spaces[self.env.agents[0]]
+        self.i = 0
+        self.action_space = spaces.Discrete(
+            self.env.action_spaces[self.env.agents[0]].n)
+
+        # if GymSpace is MultiDiscrete, then we need to convert it to Box
+        self.observation_space = GymDict({"obs": Box(
+            low=0,
+            high=observation_space.nvec.max(),
+            shape=(observation_space.nvec.shape[0],),
+            dtype=observation_space.dtype)})
+
+        self.agents = self.env.agents
+        self.num_agents = len(self.agents)
+        env_config["map_name"] = map
+        self.env_config = env_config
+
+    def reset(self):
+        self.i = 0
+        original_obs = self.env.reset()
+        obs = {}
+        for i in self.agents:
+            obs[i] = {"obs": original_obs[i]}
+        return obs
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = r[key]
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
+
+    def render(self, mode=None):
+        self.env.render()
+        time.sleep(0.05)
+        return True
+
+    def seed(self, seed=None):
+        self.env.seed(seed)
+
+    def close(self):
+        self.env.close()
+
+    def get_env_info(self):
+        env_info = {
+            "space_obs": self.observation_space,
+            "space_act": self.action_space,
+            "num_agents": self.num_agents,
+            "episode_limit": 30,
+            "policy_mapping_info": policy_mapping_dict
+        }
+        return env_info
diff --git a/marllib/envs/base_env/mcy.py b/marllib/envs/base_env/mcy.py
new file mode 100644
index 0000000..ba94fe7
--- /dev/null
+++ b/marllib/envs/base_env/mcy.py
@@ -0,0 +1,109 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+from ray.rllib.env.multi_agent_env import MultiAgentEnv
+from gym.spaces import Dict as GymDict, Discrete, Box
+import supersuit as ss
+from ray.rllib.env import PettingZooEnv, ParallelPettingZooEnv
+from omarle.movingcompany import moving_company_v0
+from gym import spaces
+
+import time
+
+REGISTRY = {}
+REGISTRY["moving_company"] = moving_company_v0.parallel_env
+
+policy_mapping_dict = {
+    "moving_company":{
+    "description": "Moving Company",
+    "team_prefix": ("agent_",),
+    "all_agents_one_policy": True,
+    "one_agent_one_policy": True,
+    }
+}
+
+class RLlibMCY(MultiAgentEnv):
+
+    def __init__(self, env_config):
+        map = env_config["map_name"]
+        env_config.pop("map_name", None)
+        env = REGISTRY[map](**env_config)
+
+        # keep obs and action dim same across agents
+        # pad_action_space_v0 will auto mask the padding actions
+        # env = ss.pad_observations_v0(env)
+        # env = ss.pad_action_space_v0(env)
+
+        self.env = ParallelPettingZooEnv(env)
+        # self.action_space = self.env.action_spaces[self.env.agents[0]]
+
+        self.action_space = spaces.Discrete(self.env.action_spaces[self.env.agents[0]].n)
+
+        # if GymSpace is MultiDiscrete, then we need to convert it to Box
+        self.observation_space = GymDict({"obs": Box(
+            low=self.env.observation_space.low[0],
+            high=self.env.observation_space.high[1],
+            shape=(self.env.observation_space.shape[0],),
+            dtype=self.env.observation_space.dtype)})
+
+        self.agents = self.env.agents
+        self.num_agents = len(self.agents)
+        env_config["map_name"] = map
+        self.env_config = env_config
+
+    def reset(self):
+        print("reset !!!!!!!!!!!!!!!!!")
+        original_obs = self.env.reset()
+        obs = {}
+        for i in self.agents:
+            obs[i] = {"obs": original_obs[i]}
+        return obs
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = r[key]
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
+
+    def close(self):
+        self.env.close()
+
+    def render(self, mode=None):
+        self.env.render()
+        time.sleep(0.05)
+        return True
+
+    def get_env_info(self):
+        env_info = {
+            "space_obs": self.observation_space,
+            "space_act": self.action_space,
+            "num_agents": self.num_agents,
+            "episode_limit": 30,
+            "policy_mapping_info": policy_mapping_dict
+        }
+        return env_info
diff --git a/marllib/envs/base_env/mpe.py b/marllib/envs/base_env/mpe.py
index 7fea8c5..fffa591 100644
--- a/marllib/envs/base_env/mpe.py
+++ b/marllib/envs/base_env/mpe.py
@@ -138,9 +138,12 @@ class RLlibMPE(MultiAgentEnv):
         self.env.close()
 
     def render(self, mode=None):
-        self.env.render()
+        if mode is None:
+            rendered = self.env.render()
+        else:
+            rendered = self.env.render(mode=mode)
         time.sleep(0.05)
-        return True
+        return rendered
 
     def get_env_info(self):
         env_info = {
diff --git a/marllib/envs/base_env/wmt.py b/marllib/envs/base_env/wmt.py
new file mode 100644
index 0000000..6c3dfc3
--- /dev/null
+++ b/marllib/envs/base_env/wmt.py
@@ -0,0 +1,108 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+from ray.rllib.env.multi_agent_env import MultiAgentEnv
+from gym.spaces import Dict as GymDict, Discrete, Box
+import supersuit as ss
+from ray.rllib.env import PettingZooEnv, ParallelPettingZooEnv
+from omarle.warehouse_management import warehouse_management_v0
+from gym import spaces
+
+import time
+
+REGISTRY = {}
+REGISTRY["warehouse_management"] = warehouse_management_v0.parallel_env
+
+policy_mapping_dict = {
+    "warehouse_management":{
+    "description": "Warehouse Management",
+    "team_prefix": ("agent_",),
+    "all_agents_one_policy": True,
+    "one_agent_one_policy": True,
+    }
+}
+
+class RLlibWMT(MultiAgentEnv):
+
+    def __init__(self, env_config):
+        map = env_config["map_name"]
+        env_config.pop("map_name", None)
+        env = REGISTRY[map](**env_config)
+
+        # keep obs and action dim same across agents
+        # pad_action_space_v0 will auto mask the padding actions
+        # env = ss.pad_observations_v0(env)
+        # env = ss.pad_action_space_v0(env)
+
+        self.env = ParallelPettingZooEnv(env)
+        # self.action_space = self.env.action_spaces[self.env.agents[0]]
+
+        self.action_space = spaces.Discrete(self.env.action_spaces[self.env.agents[0]].n)
+
+        # if GymSpace is MultiDiscrete, then we need to convert it to Box
+        self.observation_space = GymDict({"obs": Box(
+            low=self.env.observation_space.low[0],
+            high=self.env.observation_space.high[0],
+            shape=(self.env.observation_space.shape[0],),
+            dtype=self.env.observation_space.dtype)})
+
+        self.agents = self.env.agents
+        self.num_agents = len(self.agents)
+        env_config["map_name"] = map
+        self.env_config = env_config
+
+    def reset(self):
+        original_obs = self.env.reset()
+        obs = {}
+        for i in self.agents:
+            obs[i] = {"obs": original_obs[i]}
+        return obs
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = r[key]
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
+
+    def close(self):
+        self.env.close()
+
+    def render(self, mode=None):
+        self.env.render()
+        time.sleep(0.05)
+        return True
+
+    def get_env_info(self):
+        env_info = {
+            "space_obs": self.observation_space,
+            "space_act": self.action_space,
+            "num_agents": self.num_agents,
+            "episode_limit": 30,
+            "policy_mapping_info": policy_mapping_dict
+        }
+        return env_info
diff --git a/marllib/envs/global_reward_env/__init__.py b/marllib/envs/global_reward_env/__init__.py
index 1537638..90d6e51 100644
--- a/marllib/envs/global_reward_env/__init__.py
+++ b/marllib/envs/global_reward_env/__init__.py
@@ -22,6 +22,27 @@
 
 COOP_ENV_REGISTRY = {}
 
+try:
+    from marllib.envs.global_reward_env.cyborg_fcoop import RLlibCBG_FCOOP
+
+    COOP_ENV_REGISTRY["cyborg"] = RLlibCBG_FCOOP
+except Exception as e:
+    COOP_ENV_REGISTRY["cyborg"] = str(e)
+
+try:
+    from marllib.envs.global_reward_env.wmt_fcoop import RLlibWMT_FCOOP
+
+    COOP_ENV_REGISTRY["wmt"] = RLlibWMT_FCOOP
+except Exception as e:
+    COOP_ENV_REGISTRY["wmt"] = str(e)
+
+try:
+    from marllib.envs.global_reward_env.mcy_fcoop import RLlibMCY_FCOOP
+
+    COOP_ENV_REGISTRY["mcy"] = RLlibMCY_FCOOP
+except Exception as e:
+    COOP_ENV_REGISTRY["mcy"] = str(e)
+
 try:
     from marllib.envs.global_reward_env.gymnasium_mamujoco_fcoop import RLlibGymnasiumRoboticsMAMujoco_FCOOP
     COOP_ENV_REGISTRY["gymnasium_mamujoco"] = RLlibGymnasiumRoboticsMAMujoco_FCOOP
diff --git a/marllib/envs/global_reward_env/cyborg_fcoop.py b/marllib/envs/global_reward_env/cyborg_fcoop.py
new file mode 100644
index 0000000..089cda1
--- /dev/null
+++ b/marllib/envs/global_reward_env/cyborg_fcoop.py
@@ -0,0 +1,48 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+from marllib.envs.base_env.cyborg import RLlibCBG
+
+legal_scenarios = ["cage3"]
+
+
+class RLlibCBG_FCOOP(RLlibCBG):
+
+    def __init__(self, env_config):
+        if env_config["map_name"] not in legal_scenarios:
+            raise ValueError("must in: 1.cage3")
+        super().__init__(env_config)
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        reward = 0
+        for key in r.keys():
+            reward += r[key]
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = reward/self.num_agents
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
diff --git a/marllib/envs/global_reward_env/mcy_fcoop.py b/marllib/envs/global_reward_env/mcy_fcoop.py
new file mode 100644
index 0000000..e4e7baf
--- /dev/null
+++ b/marllib/envs/global_reward_env/mcy_fcoop.py
@@ -0,0 +1,48 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+from marllib.envs.base_env.mcy import RLlibMCY
+
+legal_scenarios = ["moving_company"]
+
+
+class RLlibMCY_FCOOP(RLlibMCY):
+
+    def __init__(self, env_config):
+        if env_config["map_name"] not in legal_scenarios:
+            raise ValueError("must in: 1.moving_company")
+        super().__init__(env_config)
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        reward = 0
+        for key in r.keys():
+            reward += r[key]
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = reward/self.num_agents
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
diff --git a/marllib/envs/global_reward_env/wmt_fcoop.py b/marllib/envs/global_reward_env/wmt_fcoop.py
new file mode 100644
index 0000000..e9f515d
--- /dev/null
+++ b/marllib/envs/global_reward_env/wmt_fcoop.py
@@ -0,0 +1,48 @@
+# MIT License
+
+# Copyright (c) 2023 Replicable-MARL
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+from marllib.envs.base_env.wmt import RLlibWMT
+
+legal_scenarios = ["warehouse_management"]
+
+
+class RLlibWMT_FCOOP(RLlibWMT):
+
+    def __init__(self, env_config):
+        if env_config["map_name"] not in legal_scenarios:
+            raise ValueError("must in: 1.warehouse_management")
+        super().__init__(env_config)
+
+    def step(self, action_dict):
+        o, r, d, info = self.env.step(action_dict)
+        reward = 0
+        for key in r.keys():
+            reward += r[key]
+        rewards = {}
+        obs = {}
+        for key in action_dict.keys():
+            rewards[key] = reward/self.num_agents
+            obs[key] = {
+                "obs": o[key]
+            }
+        dones = {"__all__": d["__all__"]}
+        return obs, rewards, dones, info
diff --git a/marllib/marl/__init__.py b/marllib/marl/__init__.py
index c350eb7..df6cd83 100644
--- a/marllib/marl/__init__.py
+++ b/marllib/marl/__init__.py
@@ -33,6 +33,8 @@ from ray.tune import register_env
 from copy import deepcopy
 from tabulate import tabulate
 from typing import Any, Dict, Tuple
+from mma_wrapper.organizational_model import organizational_model
+from mma_wrapper.rllibmma_wrapper import RLlibMMA_wrapper
 import yaml
 import os
 import sys
@@ -73,6 +75,8 @@ def make_env(
         environment_name: str,
         map_name: str,
         force_coop: bool = False,
+        organizational_model: organizational_model = None,
+        render_mode: str = None,
         abs_path: str = "",
         **env_params
 ) -> Tuple[MultiAgentEnv, Dict]:
@@ -144,10 +148,13 @@ def make_env(
     env_reg_name = env_config["env"] + "_" + env_config["env_args"]["map_name"]
 
     if env_config["force_coop"]:
-        register_env(env_reg_name, lambda _: COOP_ENV_REGISTRY[env_config["env"]](env_config["env_args"]))
+        register_env(env_reg_name, lambda _: 
+        RLlibMMA_wrapper(
+        COOP_ENV_REGISTRY[env_config["env"]](env_config["env_args"]),
+        organizational_model, render_mode))
         env = COOP_ENV_REGISTRY[env_config["env"]](env_config["env_args"])
     else:
-        register_env(env_reg_name, lambda _: ENV_REGISTRY[env_config["env"]](env_config["env_args"]))
+        register_env(env_reg_name, lambda _: RLlibMMA_wrapper(ENV_REGISTRY[env_config["env"]](env_config["env_args"]), organizational_model, render_mode))
         env = ENV_REGISTRY[env_config["env"]](env_config["env_args"])
 
     return env, env_config
diff --git a/marllib/marl/algos/scripts/mappo.py b/marllib/marl/algos/scripts/mappo.py
index 565cb6e..bc8d258 100644
--- a/marllib/marl/algos/scripts/mappo.py
+++ b/marllib/marl/algos/scripts/mappo.py
@@ -117,7 +117,7 @@ def run_mappo(model: Any, exp: Dict, run: Dict, env: Dict,
                        stop=stop,
                        config=config,
                        verbose=1,
-                       progress_reporter=CLIReporter(),
+                       progress_reporter=CLIReporter(max_report_frequency=10),
                        local_dir=available_local_dir if exp["local_dir"] == "" else exp["local_dir"])
 
     return results
diff --git a/requirements.txt b/requirements.txt
index 22a9f23..0bcca78 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,8 @@ torch==1.9.0
 pettingzoo==1.12.0
 pettingzoo[mpe]==1.12.0
 supersuit==3.2.0
-numpy==1.20.3
 importlib-metadata==4.13.0
 gym==0.20.0
+# gym==0.23.1
 PyYAML
+numpy==1.23.4
\ No newline at end of file
